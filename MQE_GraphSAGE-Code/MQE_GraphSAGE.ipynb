{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"L4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#MQE with GraphSAGE for Robust Graph Learning\n","\n","- **Authors:** Gad Azriel, Lidor Kupershmid  \n","- **Supervisors:** Prof. Zeev Volkovich, Dr. Renata Avros  \n","---\n","\n","## Notebook Overview:\n","This notebook implements and compares two approaches for robust graph representation learning:\n","1. **Original MQE** - Matrix-based multi-hop propagation\n","2. **MQE + GraphSAGE** - GraphSAGE-based propagation with quality estimation\n","---"],"metadata":{"id":"zuWiTmpmQkgs"}},{"cell_type":"markdown","source":["---\n","#### ***Section 1: Setup & Environment***\n","---"],"metadata":{"id":"id8WunhS9DQp"}},{"cell_type":"markdown","source":["**Install Dependencies**"],"metadata":{"id":"qulMYstvt6ms"}},{"cell_type":"code","source":["# Install PyTorch with CUDA support\n","!pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu121\n","\n","# Install PyTorch Geometric dependencies\n","!pip install --no-index torch-scatter -f https://pytorch-geometric.com/whl/torch-2.1.2+cu121.html\n","!pip install --no-index torch-sparse -f https://pytorch-geometric.com/whl/torch-2.1.2+cu121.html\n","!pip install --no-index torch-cluster -f https://pytorch-geometric.com/whl/torch-2.1.2+cu121.html\n","!pip install --no-index torch-spline-conv -f https://pytorch-geometric.com/whl/torch-2.1.2+cu121.html\n","!pip install torch-geometric\n","\n","# Install scikit-learn\n","!pip install scikit-learn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Swo7tZiOt70v","executionInfo":{"status":"ok","timestamp":1769434964864,"user_tz":-120,"elapsed":24379,"user":{"displayName":"Gad Azriel","userId":"10932247383878741785"}},"outputId":"50f1690b-bd76-4f6e-c74a-28e96075c831","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://download.pytorch.org/whl/cu121\n","\u001b[31mERROR: Could not find a version that satisfies the requirement torch==2.1.2 (from versions: 2.2.0+cu121, 2.2.1+cu121, 2.2.2+cu121, 2.3.0+cu121, 2.3.1+cu121, 2.4.0+cu121, 2.4.1+cu121, 2.5.0+cu121, 2.5.1+cu121)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for torch==2.1.2\u001b[0m\u001b[31m\n","\u001b[0mLooking in links: https://pytorch-geometric.com/whl/torch-2.1.2+cu121.html\n","\u001b[31mERROR: Could not find a version that satisfies the requirement torch-scatter (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for torch-scatter\u001b[0m\u001b[31m\n","\u001b[0mLooking in links: https://pytorch-geometric.com/whl/torch-2.1.2+cu121.html\n","\u001b[31mERROR: Could not find a version that satisfies the requirement torch-sparse (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for torch-sparse\u001b[0m\u001b[31m\n","\u001b[0mLooking in links: https://pytorch-geometric.com/whl/torch-2.1.2+cu121.html\n","\u001b[31mERROR: Could not find a version that satisfies the requirement torch-cluster (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for torch-cluster\u001b[0m\u001b[31m\n","\u001b[0mLooking in links: https://pytorch-geometric.com/whl/torch-2.1.2+cu121.html\n","\u001b[31mERROR: Could not find a version that satisfies the requirement torch-spline-conv (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for torch-spline-conv\u001b[0m\u001b[31m\n","\u001b[0mCollecting torch-geometric\n","  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.3.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2026.1.4)\n","Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n","Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-geometric\n","Successfully installed torch-geometric-2.7.0\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n"]}]},{"cell_type":"markdown","source":["##### **Create Project Structure**"],"metadata":{"id":"wVH5zr89xy_1"}},{"cell_type":"code","source":["# Create directories\n","!mkdir -p mqe_graphsage/best_params\n","%cd mqe_graphsage"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fnz4s3mhx0AE","executionInfo":{"status":"ok","timestamp":1769434977671,"user_tz":-120,"elapsed":110,"user":{"displayName":"Gad Azriel","userId":"10932247383878741785"}},"outputId":"7f489161-fd56-4b45-fe6a-c8c8013d9e2e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/mqe_graphsage\n"]}]},{"cell_type":"markdown","source":["**Create utils.py** - Helper Functions"],"metadata":{"id":"IWiqzmxPyIn8"}},{"cell_type":"code","source":["%%writefile utils.py\n","from scipy.sparse import csc_matrix\n","from sklearn.preprocessing import MinMaxScaler\n","import torch_geometric\n","import numpy as np\n","from scipy import sparse as sp\n","from sklearn.metrics import accuracy_score\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.multiclass import OneVsRestClassifier\n","from sklearn.preprocessing import normalize\n","import torch\n","import os.path as osp\n","from torch_geometric.datasets import Planetoid, Amazon, Coauthor, WikiCS\n","from torch_geometric.utils import remove_self_loops, add_self_loops\n","import json\n","\n","\n","# Puropose: Adds noise to your dataset features to test model robustness\n","# x: Our original features\n","# alpha: Percentage of samples to add noise to\n","# noise_type: Either 'uniform' or 'normal' noise distribution\n","# beta: Intensity of the noise\n","# Returns: Polluted data, indices of noisy samples, indices of clean samples\n","def polluted_feat(x, alpha, noise_type, beta):\n","    rnd_generator = np.random.RandomState(0)\n","    data_tmp = x.cpu().numpy()\n","    print('original', data_tmp.sum())\n","    num_sample, num_feat = data_tmp.shape[0], data_tmp.shape[1]\n","    num_noisy_samples = int(alpha * num_sample)\n","    noisy_indices = rnd_generator.choice(num_sample, num_noisy_samples, replace=False)\n","    clean_indices = np.setdiff1d(np.arange(num_sample), noisy_indices)\n","    print('noisy_indices', len(noisy_indices))\n","    print('clean_indices', len(clean_indices))\n","    if noise_type == 'uniform':\n","        print('uniform noise !', beta)\n","        noise = np.random.uniform(0, 1, data_tmp.shape)\n","    elif noise_type == 'normal':\n","        print('normal noise !', beta)\n","        noise = np.random.normal(0, 1, data_tmp.shape)\n","    data_tmp[noisy_indices] += beta * noise[noisy_indices]\n","    print('pollted', data_tmp.sum())\n","    return data_tmp, noisy_indices, clean_indices\n","\n","\n","# Purpose: Loads previously saved best hyperparameters from experiments\n","def load_best_params(model, dataset, alpha, noise_type, beta, path='./best_params/'):\n","    save_file = f'best_results_{model}_{dataset}.json'\n","    file_path = path + save_file\n","    try:\n","        with open(file_path, 'r') as f:\n","            results = json.load(f)\n","    except (FileNotFoundError, json.JSONDecodeError):\n","        print(f\"Error: Unable to load results from {file_path}\")\n","        return None\n","    key_str = f\"{alpha}_{beta}_{noise_type}\"\n","    if model in results and key_str in results[model]:\n","        best_params = results[model][key_str]['best_params']\n","        return best_params\n","    else:\n","        print(f\"No best params found for model '{model}', dataset '{dataset}', alpha '{alpha}', noise_type '{noise_type}', beta '{beta}'\")\n","        return None\n","\n","\n","# Purpose: Loads standard graph datasets (Cora, CiteSeer, etc.)\n","def load_data(name):\n","    path = osp.join('./', 'data')\n","    if name in ['Cora', 'CiteSeer', 'PubMed']:\n","        dataset = Planetoid(path, name)\n","    elif name in ['computers', 'photo']:\n","        dataset = Amazon(path, name)\n","    elif name in ['cs', 'physics']:\n","        dataset = Coauthor(path, name)\n","    elif name in ['wikics']:\n","        dataset = WikiCS(path)\n","\n","    data = dataset[0]\n","    data.edge_index = remove_self_loops(data.edge_index)[0]\n","    data.edge_index = add_self_loops(data.edge_index)[0]\n","    data.num_classes = torch.max(data.y).item() + 1\n","    data.x = Norm(data.x)\n","    adj = edge_index_to_sparse_mx(data.edge_index, data.num_nodes)\n","    data.A = adj\n","    adj = process_adj(adj)\n","    data.adj = adj\n","    return data\n","\n","\n","# Purpose: Converts scipy sparse matrices to PyTorch sparse tensors\n","def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n","    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n","    indices = torch.from_numpy(\n","        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n","    values = torch.from_numpy(sparse_mx.data)\n","    shape = torch.Size(sparse_mx.shape)\n","    return torch.sparse.FloatTensor(indices, values, shape)\n","\n","\n","# Purpose: Sets random seeds for reproducibility\n","def set_seeds(seed):\n","    np.random.seed(seed)\n","    torch_geometric.seed_everything(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","\n","\n","# Purpose: Normalizes features to range [0,1] or [-1,1]\n","# Neural networks train better with normalized inputs\n","def Norm(x, min=0):\n","    x = x.detach().cpu().numpy()\n","    if min == 0:\n","        scaler = MinMaxScaler((0, 1))\n","    else:\n","        scaler = MinMaxScaler((-1, 1))\n","    norm_x = torch.tensor(scaler.fit_transform(x))\n","    if torch.cuda.is_available():\n","        norm_x = norm_x.cuda()\n","    return norm_x\n","\n","\n","# Purpose: Performs K-hop message passing on the graph\n","# norm_A: Normalized adjacency matrix\n","# K: Number of hops/iterations\n","## This is the core of how GraphSAGE spreads information!\n","def MessagePro(data, norm_A, K):\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    data = data.to(device)\n","    norm_A = norm_A.to(device)\n","    X_list = [data]\n","    for _ in range(K):\n","        X_list.append(torch.spmm(norm_A, X_list[-1]))\n","\n","    return X_list\n","\n","\n","# Purpose: Tests embedding quality using logistic regression\n","def label_classification(X, Y):\n","    X = normalize(X, norm='l2')\n","    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.8)\n","\n","    logreg = LogisticRegression(solver='liblinear')\n","    c = 2.0 ** np.arange(-10, 10)\n","\n","    clf = GridSearchCV(estimator=OneVsRestClassifier(logreg),\n","                       param_grid=dict(estimator__C=c), n_jobs=8, cv=5,\n","                       verbose=0)\n","    clf.fit(X_train, y_train)\n","    y_pred_test = clf.predict(X_test)\n","    acc_test = accuracy_score(y_test, y_pred_test)\n","\n","    return acc_test * 100\n","\n","\n","# Purpose: Converts edge list format to adjacency matrix\n","def edge_index_to_sparse_mx(edge_index, num_nodes):\n","    edge_weight = np.array([1] * len(edge_index[0]))\n","    adj = csc_matrix((edge_weight, (edge_index[0], edge_index[1])),\n","                     shape=(num_nodes, num_nodes)).tolil()\n","    return adj\n","\n","\n","# Purpose: Normalizes the adjacency matrix using symmetric normalization\n","def normalize_adj(adj):\n","    # Add self-loops\n","    adj = adj + sp.eye(adj.shape[0])\n","    # Compute degree matrix\n","    rowsum = np.array(adj.sum(1))\n","    # Compute D^{-1/2}\n","    d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n","    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n","    # Compute D^{-1/2}AD^{-1/2}\n","    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n","    return adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt)\n","\n","\n","def process_adj(adj):\n","    adj.setdiag(1)\n","    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n","    adj = normalize_adj(adj)\n","    adj = sparse_mx_to_torch_sparse_tensor(adj)\n","    return adj"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fdG4HBp_yJoQ","executionInfo":{"status":"ok","timestamp":1769435026807,"user_tz":-120,"elapsed":17,"user":{"displayName":"Gad Azriel","userId":"10932247383878741785"}},"outputId":"b83f10b6-389b-4d96-f45c-d794742d24ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing utils.py\n"]}]},{"cell_type":"markdown","source":["**Create model_graphsage.py** - Neural Network Models"],"metadata":{"id":"-ZrhjkzjyS9l"}},{"cell_type":"code","source":["%%writefile model_graphsage.py\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch_geometric.nn import SAGEConv\n","\n","\n","# Purpose: The GraphSAGE component that aggregates information from neighbors\n","class GraphSAGEEncoder(nn.Module):\n","    def __init__(self, input_dim, hidden_dims, num_layers, aggregator='mean'):\n","        super(GraphSAGEEncoder, self).__init__()\n","        self.num_layers = num_layers\n","        self.convs = nn.ModuleList()\n","\n","        # First layer\n","        self.convs.append(SAGEConv(input_dim, hidden_dims[0], aggr=aggregator))\n","\n","        # Hidden layers\n","        for i in range(1, num_layers):\n","            self.convs.append(SAGEConv(hidden_dims[i-1], hidden_dims[i], aggr=aggregator))\n","\n","    def forward(self, x, edge_index):\n","        \"\"\"\n","        Returns embeddings at each layer (multi-hop features)\n","        \"\"\"\n","        embeddings = [x]  # h^(0) = x\n","\n","        for i, conv in enumerate(self.convs):\n","            x = conv(x, edge_index)\n","            x = F.relu(x)\n","            embeddings.append(x)  # h^(1), h^(2), ..., h^(L)\n","\n","        return embeddings\n","\n","\n","class MQEQualityEstimator(nn.Module):\n","    \"\"\"\n","    Estimates mean (μ) and variance (σ²) for feature quality estimation\n","    \"\"\"\n","    def __init__(self, z_dim, feat_dim, hid_dim):\n","        super(MQEQualityEstimator, self).__init__()\n","        # Expectation Network (predicts mean μ)\n","        self.E_MLP = nn.Sequential(\n","            nn.Linear(z_dim, hid_dim[0]),\n","            nn.ReLU(),\n","            nn.Linear(hid_dim[0], feat_dim)\n","        )\n","        # Quality Network (predicts variance σ)\n","        self.Q_MLP = nn.Sequential(\n","            nn.Linear(z_dim, hid_dim[1]),\n","            nn.ReLU(),\n","            nn.Linear(hid_dim[1], 1),\n","            nn.Softplus()\n","        )\n","\n","    def forward(self, Z):\n","        mean = self.E_MLP(Z)\n","        sigma = self.Q_MLP(Z)\n","        return mean, sigma\n","\n","\n","class MQE_GraphSAGE(nn.Module):\n","    \"\"\"\n","    Combined model: GraphSAGE for propagation + MQE for quality estimation\n","    \"\"\"\n","    def __init__(self, input_dim, z_dim, sage_hidden_dims, mqe_hid_dims, num_layers, aggregator='mean'):\n","        super(MQE_GraphSAGE, self).__init__()\n","\n","        self.num_layers = num_layers\n","        self.z_dim = z_dim\n","\n","        # GraphSAGE encoder\n","        self.sage_encoder = GraphSAGEEncoder(input_dim, sage_hidden_dims, num_layers, aggregator)\n","\n","        # MQE quality estimators (one per layer)\n","        self.mqe_estimators = nn.ModuleList()\n","        for i in range(num_layers + 1):  # +1 for the initial features\n","            if i == 0:\n","                feat_dim = input_dim\n","            else:\n","                feat_dim = sage_hidden_dims[i-1]\n","\n","            estimator = MQEQualityEstimator(z_dim, feat_dim, mqe_hid_dims)\n","            self.mqe_estimators.append(estimator)\n","\n","    def forward(self, x, edge_index, Z):\n","        \"\"\"\n","        x: node features\n","        edge_index: graph structure\n","        Z: meta-representation for each node\n","\n","        Returns: means and sigmas for each layer\n","        \"\"\"\n","        # Get multi-hop embeddings from GraphSAGE\n","        embeddings = self.sage_encoder(x, edge_index)\n","\n","        # Estimate quality for each layer\n","        means = []\n","        sigmas = []\n","\n","        for i, embedding in enumerate(embeddings):\n","            mean, sigma = self.mqe_estimators[i](Z)\n","            means.append(mean)\n","            sigmas.append(sigma)\n","\n","        return embeddings, means, sigmas\n","\n","\n","# Simple MQE model (original, for comparison)\n","class MQENet(nn.Module):\n","    def __init__(self, z_dim, feat_dim, hid_dim):\n","        super(MQENet, self).__init__()\n","        # Expectation\n","        self.E_MLP = nn.Sequential(nn.Linear(z_dim, hid_dim[0]), nn.ReLU(),\n","                                   nn.Linear(hid_dim[0], feat_dim))\n","        # Variance (Quality)\n","        self.Q_MLP = nn.Sequential(nn.Linear(z_dim, hid_dim[1]), nn.ReLU(),\n","                                   nn.Linear(hid_dim[1], 1), nn.Softplus())\n","\n","    def forward(self, Z):\n","        mean = self.E_MLP(Z)\n","        sigma = self.Q_MLP(Z)\n","        return mean, sigma"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hz-0ZV_0yUra","executionInfo":{"status":"ok","timestamp":1769435030742,"user_tz":-120,"elapsed":37,"user":{"displayName":"Gad Azriel","userId":"10932247383878741785"}},"outputId":"4a415a68-94d4-41c8-a02f-c3de216c0a86"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing model_graphsage.py\n"]}]},{"cell_type":"markdown","source":["**Create train_graphsage.py** - Training Functions"],"metadata":{"id":"CB-bCoydzXlP"}},{"cell_type":"code","source":["%%writefile train_graphsage.py\n","import torch\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from model_graphsage import MQENet\n","from itertools import chain\n","from torch.nn import ModuleList\n","\n","\n","def train_mqe_graphsage(dataset, args):\n","    \"\"\"\n","    Train MQE with GraphSAGE-based propagation\n","    Two-stage approach:\n","    1. Train GraphSAGE with supervision\n","    2. Use trained GraphSAGE embeddings for MQE quality estimation\n","    \"\"\"\n","    device = torch.device(args.device if args.cuda else 'cpu')\n","\n","    from model_graphsage import GraphSAGEEncoder\n","\n","    # Stage 1: Train GraphSAGE for node classification\n","    print(\"Stage 1: Training GraphSAGE encoder...\")\n","    sage_encoder = GraphSAGEEncoder(\n","        input_dim=args.input_dim,\n","        hidden_dims=args.sage_hidden_dims,\n","        num_layers=args.num_hops,\n","        aggregator=args.aggregator\n","    ).to(device)\n","\n","    # Add a classifier on top\n","    classifier = torch.nn.Linear(args.sage_hidden_dims[-1], dataset.num_classes).to(device)\n","\n","    # Create train/val split (same as used for final evaluation)\n","    from sklearn.model_selection import train_test_split\n","    indices = torch.arange(dataset.num_nodes)\n","    train_idx, val_idx = train_test_split(\n","        indices.numpy(),\n","        test_size=0.8,\n","        random_state=42,\n","        stratify=dataset.y.cpu().numpy()\n","    )\n","    train_idx = torch.LongTensor(train_idx).to(device)\n","    val_idx = torch.LongTensor(val_idx).to(device)\n","\n","    x = dataset.x.to(device)\n","    edge_index = dataset.edge_index.to(device)\n","    y = dataset.y.to(device)\n","\n","    # Train GraphSAGE\n","    optimizer_sage = optim.Adam(\n","        list(sage_encoder.parameters()) + list(classifier.parameters()),\n","        lr=args.lr\n","    )\n","\n","    best_val_acc = 0\n","    patience = 20\n","    patience_counter = 0\n","\n","    for epoch in range(1, min(args.epochs, 100) + 1):  # Max 100 epochs for GraphSAGE\n","        sage_encoder.train()\n","        classifier.train()\n","        optimizer_sage.zero_grad()\n","\n","        # Forward\n","        embeddings = sage_encoder(x, edge_index)\n","        final_emb = embeddings[-1]  # Use last layer\n","        out = classifier(final_emb)\n","\n","        # Loss only on training nodes\n","        loss = F.cross_entropy(out[train_idx], y[train_idx])\n","        loss.backward()\n","        optimizer_sage.step()\n","\n","        # Validation\n","        if epoch % 10 == 0:\n","            sage_encoder.eval()\n","            classifier.eval()\n","            with torch.no_grad():\n","                embeddings = sage_encoder(x, edge_index)\n","                out = classifier(embeddings[-1])\n","                pred = out.argmax(dim=1)\n","                val_acc = (pred[val_idx] == y[val_idx]).float().mean().item()\n","\n","                if val_acc > best_val_acc:\n","                    best_val_acc = val_acc\n","                    patience_counter = 0\n","                else:\n","                    patience_counter += 1\n","\n","                if epoch % 20 == 0:\n","                    print(f'  Epoch {epoch}, Loss: {loss.item():.4f}, Val Acc: {val_acc:.4f}')\n","\n","        if patience_counter >= patience:\n","            print(f\"  Early stopping at epoch {epoch}\")\n","            break\n","\n","    print(f\"Stage 1 complete. Best val acc: {best_val_acc:.4f}\")\n","\n","    # Stage 2: Get trained embeddings and apply MQE\n","    print(\"\\nStage 2: Applying MQE quality estimation...\")\n","    sage_encoder.eval()\n","    with torch.no_grad():\n","        embeddings = sage_encoder(x, edge_index)\n","\n","    # Now apply MQE to these trained embeddings\n","    model_list = []\n","    for i, emb in enumerate(embeddings):\n","        feat_dim = emb.shape[1]\n","        model_temp = MQENet(args.z_dim, feat_dim, args.hid_dim).to(device)\n","        model_list.append(model_temp)\n","\n","    # Initialize meta-representation Z\n","    Z = torch.normal(mean=torch.zeros([dataset.num_nodes, args.z_dim]), std=0.01)\n","    Z = Z.to(device)\n","    Z.requires_grad_(True)\n","\n","    model_list = ModuleList(model_list)\n","    optimizer = optim.Adam(chain(model_list.parameters(), [Z]), lr=args.lr)\n","\n","    # Training loop for MQE\n","    for epoch in range(1, args.epochs + 1):\n","        loss = 0\n","        model_list.train()\n","\n","        for v in range(len(embeddings)):\n","            x_re, sigma = model_list[v](Z)\n","            re_loss = (x_re - embeddings[v]) ** 2\n","            re_loss = re_loss.div(2 * sigma ** 2) + torch.log(sigma)\n","            re_loss = re_loss.mean(1, keepdim=True)\n","            loss = loss + re_loss.mean()\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if epoch % 50 == 0 or epoch == 1:\n","            print(f'  Epoch {epoch}/{args.epochs}, Loss: {loss.item():.4f}')\n","\n","    return Z.detach().cpu().numpy()\n","\n","\n","def train_mqe_original(dataset, args):\n","    \"\"\"\n","    Train original MQE (matrix-based propagation) for comparison\n","    \"\"\"\n","    device = torch.device(args.device if args.cuda else 'cpu')\n","\n","    # Create one MQE model per hop\n","    model_list = []\n","    X_list = dataset.X_list\n","\n","    for v in range(len(X_list)):\n","        feat_dim = X_list[v].shape[1]\n","        model_temp = MQENet(args.z_dim, feat_dim, args.hid_dim).to(device)\n","        model_list.append(model_temp)\n","\n","    # Initialize meta-representation Z\n","    Z = torch.normal(mean=torch.zeros([dataset.num_nodes, args.z_dim]), std=0.01)\n","    Z = Z.to(device)\n","    Z.requires_grad_(True)\n","\n","    # Optimizer\n","    model_list = ModuleList(model_list)\n","    optimizer = optim.Adam(chain(model_list.parameters(), [Z]), lr=args.lr)\n","\n","    # Training loop\n","    for epoch in range(1, args.epochs + 1):\n","        loss = 0\n","        model_list.train()\n","\n","        for v in range(len(X_list)):\n","            x_re, sigma = model_list[v](Z)\n","            re_loss = (x_re - X_list[v]) ** 2\n","            re_loss = re_loss.div(2 * sigma ** 2) + torch.log(sigma)\n","            re_loss = re_loss.mean(1, keepdim=True)\n","            loss = loss + re_loss.mean()\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if epoch % 50 == 0 or epoch == 1:\n","            print(f'Epoch {epoch}/{args.epochs}, Loss: {loss.item():.4f}')\n","\n","    return Z.detach().cpu().numpy()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-7c01nQWzY3C","executionInfo":{"status":"ok","timestamp":1769435033417,"user_tz":-120,"elapsed":15,"user":{"displayName":"Gad Azriel","userId":"10932247383878741785"}},"outputId":"ee0562ce-b54d-4bd5-c81f-df6cd1e7b3d4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing train_graphsage.py\n"]}]},{"cell_type":"markdown","source":["**Create run_comparison.py** - Experimental Comparison Script"],"metadata":{"id":"6U8EGqGSEA8E"}},{"cell_type":"code","source":["%%writefile run_comparison.py\n","import torch\n","import argparse\n","from utils import *\n","from train_graphsage import train_mqe_graphsage, train_mqe_original\n","from sklearn.neighbors import kneighbors_graph\n","import warnings\n","import numpy as np\n","import time\n","\n","\n","def parameter_parser():\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--epochs', type=int, default=1000, help='training epochs')\n","    parser.add_argument('--lr', type=float, default=0.002, help='learning rate')\n","    parser.add_argument('--z-dim', type=int, default=512, help='meta-representation dimension')\n","    parser.add_argument('--hid-dim', type=list, default=[256, 64], help='MQE hidden dims')\n","    parser.add_argument('--sage-hidden-dims', type=list, default=[128, 128], help='GraphSAGE hidden dims')\n","    parser.add_argument('--data-name', type=str, default='Cora', help='dataset name')\n","    parser.add_argument('--num-hops', type=int, default=2, help='number of hops/layers')\n","    parser.add_argument('--device', type=str, default='cuda')\n","    parser.add_argument('--num-neighbor', type=int, default=20)\n","    parser.add_argument('--alpha', type=float, default=0.5, help='noisy node fraction')\n","    parser.add_argument('--beta', type=float, default=0.5, help='noise level')\n","    parser.add_argument('--noise-type', type=str, default='normal', choices=['normal', 'uniform', 'Original'])\n","    parser.add_argument('--aggregator', type=str, default='mean', choices=['mean', 'max', 'lstm'])\n","    parser.add_argument('--ntrials', type=int, default=3, help='number of trials')\n","    args = parser.parse_known_args()[0]\n","    return args\n","\n","\n","def get_knn_graph(x, num_neighbor, knn_metric='cosine'):\n","    adj_knn = kneighbors_graph(x, num_neighbor, metric=knn_metric)\n","    return adj_knn.tolil()\n","\n","\n","def run_experiment(use_graphsage=True):\n","    \"\"\"\n","    Run experiment with either MQE+GraphSAGE or Original MQE\n","    \"\"\"\n","    warnings.filterwarnings(\"ignore\")\n","    set_seeds(0)\n","    args = parameter_parser()\n","\n","    if torch.cuda.is_available():\n","        args.cuda = True\n","    else:\n","        args.cuda = False\n","\n","    device = torch.device(args.device if args.cuda else 'cpu')\n","\n","    # Load dataset\n","    dataset = load_data(args.data_name)\n","    dataset.ori_x = dataset.x.cpu().clone()\n","\n","    # Add noise if requested\n","    if args.noise_type != 'Original':\n","        data_tmp, noisy_indices, clean_indices = polluted_feat(\n","            dataset.x, args.alpha, args.noise_type, args.beta\n","        )\n","        data_tmp = torch.from_numpy(data_tmp)\n","        dataset.x = data_tmp\n","        args.noise_idx = noisy_indices\n","        args.clean_idx = clean_indices\n","\n","    dataset.x = dataset.x.to(device)\n","    args.input_dim = dataset.num_node_features\n","    args.num_class = dataset.num_classes\n","\n","    if use_graphsage:\n","        print(\"\\n\" + \"=\"*60)\n","        print(\"Running MQE + GraphSAGE\")\n","        print(\"=\"*60)\n","    else:\n","        print(\"\\n\" + \"=\"*60)\n","        print(\"Running Original MQE (Matrix-based)\")\n","        print(\"=\"*60)\n","        # Prepare multi-hop features for original MQE\n","        feat_ = MessagePro(dataset.x, dataset.adj, args.num_hops)\n","        feat = torch.stack(feat_).sum(dim=0)\n","        adj_f = get_knn_graph(feat.cpu(), args.num_neighbor, knn_metric='cosine')\n","        adj_f = process_adj(adj_f)\n","        x_f = MessagePro(dataset.x, (dataset.adj + adj_f) / 2, args.num_hops)\n","        dataset.X_list = x_f\n","\n","    # Run multiple trials\n","    accs = []\n","    times = []\n","\n","    for trial in range(1, args.ntrials + 1):\n","        print(f\"\\n--- Trial {trial}/{args.ntrials} ---\")\n","        set_seeds(trial)\n","\n","        start_time = time.time()\n","\n","        if use_graphsage:\n","            H = train_mqe_graphsage(dataset, args)\n","        else:\n","            H = train_mqe_original(dataset, args)\n","\n","        elapsed_time = time.time() - start_time\n","        times.append(elapsed_time)\n","\n","        Y = dataset.y.detach().cpu().numpy()\n","        acc_test = label_classification(H, Y)\n","\n","        print(f'Accuracy: {acc_test:.2f}%, Time: {elapsed_time:.2f}s')\n","        accs.append(acc_test)\n","\n","    avg_acc = round(np.mean(accs), 2)\n","    std_acc = round(np.std(accs), 2)\n","    avg_time = round(np.mean(times), 2)\n","\n","    return avg_acc, std_acc, avg_time\n","\n","\n","if __name__ == \"__main__\":\n","    # Run both approaches\n","    print(\"\\n\" + \"PHASE B: COMPARATIVE EXPERIMENTS \".center(60, \"=\"))\n","\n","    # Approach 1: Original MQE\n","    acc_orig, std_orig, time_orig = run_experiment(use_graphsage=False)\n","\n","    # Approach 2: MQE + GraphSAGE\n","    acc_sage, std_sage, time_sage = run_experiment(use_graphsage=True)\n","\n","    # Summary\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"FINAL RESULTS SUMMARY\")\n","    print(\"=\"*60)\n","    print(f\"\\n{'Method':<30} {'Accuracy':<15} {'Time (s)':<10}\")\n","    print(\"-\" * 60)\n","    print(f\"{'Original MQE':<30} {acc_orig}\\u00b1{std_orig}%{'':<10} {time_orig}\")\n","    print(f\"{'MQE + GraphSAGE':<30} {acc_sage}\\u00b1{std_sage}%{'':<10} {time_sage}\")\n","    print(\"=\"*60)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ttGP-Su-yYxh","executionInfo":{"status":"ok","timestamp":1769435041844,"user_tz":-120,"elapsed":12,"user":{"displayName":"Gad Azriel","userId":"10932247383878741785"}},"outputId":"d617724e-8065-4e75-e9ea-b12f9c92d519"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing run_comparison.py\n"]}]},{"cell_type":"markdown","source":["---\n","#### ***Section 2: Output***\n","---"],"metadata":{"id":"qLcYDzHDH2Kr"}},{"cell_type":"markdown","source":["**Run the Comparison Experiment**"],"metadata":{"id":"raJfTbmDzd7Q"}},{"cell_type":"code","source":["!python run_comparison.py"],"metadata":{"id":"4FuQHagfEoy7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1769435122029,"user_tz":-120,"elapsed":77073,"user":{"displayName":"Gad Azriel","userId":"10932247383878741785"}},"outputId":"325307e8-cbd6-45c8-f517-a7e4c4608fa4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=============PHASE B: COMPARATIVE EXPERIMENTS ==============\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n","Processing...\n","Done!\n","original 49216.0\n","noisy_indices 1354\n","clean_indices 1354\n","normal noise ! 0.5\n","pollted 49499.83\n","\n","============================================================\n","Running Original MQE (Matrix-based)\n","============================================================\n","\n","--- Trial 1/3 ---\n","Epoch 1/1000, Loss: -0.9347\n","Epoch 50/1000, Loss: -4.8748\n","Epoch 100/1000, Loss: -5.0431\n","Epoch 150/1000, Loss: -5.3075\n","Epoch 200/1000, Loss: -5.5219\n","Epoch 250/1000, Loss: -5.6539\n","Epoch 300/1000, Loss: -5.7366\n","Epoch 350/1000, Loss: -5.7717\n","Epoch 400/1000, Loss: -5.8160\n","Epoch 450/1000, Loss: -5.8227\n","Epoch 500/1000, Loss: -5.9218\n","Epoch 550/1000, Loss: -5.9456\n","Epoch 600/1000, Loss: -5.9790\n","Epoch 650/1000, Loss: -5.9497\n","Epoch 700/1000, Loss: -5.9125\n","Epoch 750/1000, Loss: -6.0493\n","Epoch 800/1000, Loss: -6.0819\n","Epoch 850/1000, Loss: -6.0430\n","Epoch 900/1000, Loss: -6.0072\n","Epoch 950/1000, Loss: -6.1036\n","Epoch 1000/1000, Loss: -6.1559\n","Accuracy: 68.76%, Time: 7.95s\n","\n","--- Trial 2/3 ---\n","Epoch 1/1000, Loss: -0.9494\n","Epoch 50/1000, Loss: -4.8082\n","Epoch 100/1000, Loss: -5.0566\n","Epoch 150/1000, Loss: -5.3347\n","Epoch 200/1000, Loss: -5.5416\n","Epoch 250/1000, Loss: -5.6691\n","Epoch 300/1000, Loss: -5.7473\n","Epoch 350/1000, Loss: -5.7962\n","Epoch 400/1000, Loss: -5.7804\n","Epoch 450/1000, Loss: -5.8592\n","Epoch 500/1000, Loss: -5.8767\n","Epoch 550/1000, Loss: -5.8915\n","Epoch 600/1000, Loss: -5.9475\n","Epoch 650/1000, Loss: -5.9649\n","Epoch 700/1000, Loss: -5.9494\n","Epoch 750/1000, Loss: -6.0188\n","Epoch 800/1000, Loss: -6.0477\n","Epoch 850/1000, Loss: -6.0276\n","Epoch 900/1000, Loss: -6.1258\n","Epoch 950/1000, Loss: -6.0010\n","Epoch 1000/1000, Loss: -6.1578\n","Accuracy: 67.42%, Time: 7.39s\n","\n","--- Trial 3/3 ---\n","Epoch 1/1000, Loss: -0.9645\n","Epoch 50/1000, Loss: -4.8731\n","Epoch 100/1000, Loss: -5.0709\n","Epoch 150/1000, Loss: -5.3667\n","Epoch 200/1000, Loss: -5.5889\n","Epoch 250/1000, Loss: -5.7235\n","Epoch 300/1000, Loss: -5.7952\n","Epoch 350/1000, Loss: -5.8522\n","Epoch 400/1000, Loss: -5.8688\n","Epoch 450/1000, Loss: -5.9316\n","Epoch 500/1000, Loss: -5.9574\n","Epoch 550/1000, Loss: -5.9592\n","Epoch 600/1000, Loss: -6.0091\n","Epoch 650/1000, Loss: -6.0157\n","Epoch 700/1000, Loss: -6.0773\n","Epoch 750/1000, Loss: -6.0492\n","Epoch 800/1000, Loss: -6.0827\n","Epoch 850/1000, Loss: -6.1453\n","Epoch 900/1000, Loss: -6.1368\n","Epoch 950/1000, Loss: -6.0834\n","Epoch 1000/1000, Loss: -6.1753\n","Accuracy: 70.05%, Time: 7.42s\n","original 49216.0\n","noisy_indices 1354\n","clean_indices 1354\n","normal noise ! 0.5\n","pollted 49499.83\n","\n","============================================================\n","Running MQE + GraphSAGE\n","============================================================\n","\n","--- Trial 1/3 ---\n","Stage 1: Training GraphSAGE encoder...\n","  Epoch 20, Loss: 0.0142, Val Acc: 0.7337\n","  Epoch 40, Loss: 0.0001, Val Acc: 0.7314\n","  Epoch 60, Loss: 0.0000, Val Acc: 0.7291\n","  Epoch 80, Loss: 0.0000, Val Acc: 0.7305\n","  Epoch 100, Loss: 0.0000, Val Acc: 0.7314\n","Stage 1 complete. Best val acc: 0.7337\n","\n","Stage 2: Applying MQE quality estimation...\n","  Epoch 1/1000, Loss: 11.7347\n","  Epoch 50/1000, Loss: 0.2432\n","  Epoch 100/1000, Loss: -0.4114\n","  Epoch 150/1000, Loss: -1.7624\n","  Epoch 200/1000, Loss: -2.8180\n","  Epoch 250/1000, Loss: -3.2301\n","  Epoch 300/1000, Loss: -3.5869\n","  Epoch 350/1000, Loss: -4.2197\n","  Epoch 400/1000, Loss: -4.3214\n","  Epoch 450/1000, Loss: -3.9502\n","  Epoch 500/1000, Loss: -5.4539\n","  Epoch 550/1000, Loss: -3.6315\n","  Epoch 600/1000, Loss: -3.0546\n","  Epoch 650/1000, Loss: -5.8637\n","  Epoch 700/1000, Loss: -6.1301\n","  Epoch 750/1000, Loss: -6.0602\n","  Epoch 800/1000, Loss: -4.9879\n","  Epoch 850/1000, Loss: -3.7978\n","  Epoch 900/1000, Loss: -3.9246\n","  Epoch 950/1000, Loss: -1.0118\n","  Epoch 1000/1000, Loss: -2.8431\n","Accuracy: 79.28%, Time: 5.48s\n","\n","--- Trial 2/3 ---\n","Stage 1: Training GraphSAGE encoder...\n","  Epoch 20, Loss: 0.0136, Val Acc: 0.7314\n","  Epoch 40, Loss: 0.0001, Val Acc: 0.7342\n","  Epoch 60, Loss: 0.0000, Val Acc: 0.7365\n","  Epoch 80, Loss: 0.0000, Val Acc: 0.7365\n","  Epoch 100, Loss: 0.0000, Val Acc: 0.7374\n","Stage 1 complete. Best val acc: 0.7379\n","\n","Stage 2: Applying MQE quality estimation...\n","  Epoch 1/1000, Loss: 10.7563\n","  Epoch 50/1000, Loss: 0.3319\n","  Epoch 100/1000, Loss: -0.4070\n","  Epoch 150/1000, Loss: -1.8026\n","  Epoch 200/1000, Loss: -2.7518\n","  Epoch 250/1000, Loss: -3.1363\n","  Epoch 300/1000, Loss: -3.6732\n","  Epoch 350/1000, Loss: -3.9034\n","  Epoch 400/1000, Loss: -4.7451\n","  Epoch 450/1000, Loss: -5.3478\n","  Epoch 500/1000, Loss: -2.9659\n","  Epoch 550/1000, Loss: -5.3901\n","  Epoch 600/1000, Loss: -3.6858\n","  Epoch 650/1000, Loss: -6.1242\n","  Epoch 700/1000, Loss: -3.5045\n","  Epoch 750/1000, Loss: -3.9140\n","  Epoch 800/1000, Loss: -4.6444\n","  Epoch 850/1000, Loss: -0.2043\n","  Epoch 900/1000, Loss: -2.8168\n","  Epoch 950/1000, Loss: -4.9587\n","  Epoch 1000/1000, Loss: -5.0177\n","Accuracy: 79.37%, Time: 5.18s\n","\n","--- Trial 3/3 ---\n","Stage 1: Training GraphSAGE encoder...\n","  Epoch 20, Loss: 0.0125, Val Acc: 0.7296\n","  Epoch 40, Loss: 0.0001, Val Acc: 0.7337\n","  Epoch 60, Loss: 0.0000, Val Acc: 0.7337\n","  Epoch 80, Loss: 0.0000, Val Acc: 0.7342\n","  Epoch 100, Loss: 0.0000, Val Acc: 0.7337\n","Stage 1 complete. Best val acc: 0.7342\n","\n","Stage 2: Applying MQE quality estimation...\n","  Epoch 1/1000, Loss: 9.9327\n","  Epoch 50/1000, Loss: 0.2927\n","  Epoch 100/1000, Loss: -0.4756\n","  Epoch 150/1000, Loss: -2.0994\n","  Epoch 200/1000, Loss: -2.8973\n","  Epoch 250/1000, Loss: -3.3694\n","  Epoch 300/1000, Loss: -3.8585\n","  Epoch 350/1000, Loss: -4.5702\n","  Epoch 400/1000, Loss: -4.5247\n","  Epoch 450/1000, Loss: -5.1356\n","  Epoch 500/1000, Loss: -5.5571\n","  Epoch 550/1000, Loss: -6.3160\n","  Epoch 600/1000, Loss: -5.5498\n","  Epoch 650/1000, Loss: -6.3502\n","  Epoch 700/1000, Loss: -3.6910\n","  Epoch 750/1000, Loss: -5.9909\n","  Epoch 800/1000, Loss: -6.4443\n","  Epoch 850/1000, Loss: -4.6648\n","  Epoch 900/1000, Loss: -5.1062\n","  Epoch 950/1000, Loss: -4.7387\n","  Epoch 1000/1000, Loss: -2.4482\n","Accuracy: 79.42%, Time: 5.22s\n","\n","============================================================\n","FINAL RESULTS SUMMARY\n","============================================================\n","\n","Method                         Accuracy        Time (s)  \n","------------------------------------------------------------\n","Original MQE                   68.74±1.07%           7.59\n","MQE + GraphSAGE                79.36±0.06%           5.29\n","============================================================\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"INEZpaTwe2Uv"},"execution_count":null,"outputs":[]}]}